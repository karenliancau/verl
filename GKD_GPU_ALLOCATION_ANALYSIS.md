## GKD GPUåˆ†é… - æ·±åº¦åˆ†æ

### ğŸ¯ é—®é¢˜æ¾„æ¸…

ä½ çš„æ€€ç–‘**å®Œå…¨æ­£ç¡®**ï¼GPUåˆ†é…ç¡®å®æœ‰é—®é¢˜ï¼Œå…³é”®æ˜¯è¦ç†è§£GKDä¸­ **Actor å’Œ Rollout** çš„åŠ è½½æ–¹å¼ã€‚

---

## æ¶æ„åˆ†æ

### 1. Resource Pool åˆ†é…æœºåˆ¶

**é…ç½®**: `recipe/gkd/config/on_policy_distill_trainer.yaml`
```yaml
trainer:
  n_gpus_per_node: 2   # Actor ç”¨ 2 å¼ å¡
  nnodes: 1

rollout:
  n_gpus_per_node: 2   # Rollout ç”¨ 2 å¼ å¡
  nnodes: 1
```

**GKD ä¸­çš„ ResourcePoolManager** (`main_gkd.py` ç¬¬182-189è¡Œ):
```python
actor_pool = [config.trainer.n_gpus_per_node] * config.trainer.nnodes  # [2]
rollout_pool = [config.rollout.n_gpus_per_node] * config.rollout.nnodes  # [2]

resource_pool_spec = {
    "rollout_pool": rollout_pool,  # [2] â†’ GPU 0-1
    "actor_pool": actor_pool,       # [2] â†’ GPU 2-3  
}
```

**GPU åˆ†é…ç»“æœ** (8å¡æœºå™¨):
- GPU 0-1: Rollout Worker (ç”Ÿæˆåºåˆ—)
- GPU 2-3: Actor Worker (è®­ç»ƒæ¨¡å‹)
- GPU 4-7: Teacher Server (ç‹¬ç«‹å¯åŠ¨ï¼Œå•ç‹¬è¿›ç¨‹)

---

## å…³é”®é—®é¢˜ï¼šæ¨¡å‹åŠ è½½é€»è¾‘

### é—®é¢˜ 1ï¼šActor Worker åŠ è½½ä»€ä¹ˆæ¨¡å‹ï¼Ÿ

**æ–‡ä»¶**: `recipe/gkd/megatron_workers.py` ç¬¬480-537è¡Œ

```python
class MegatronOnPolicyDistillActorWorker(ActorRolloutRefWorker):
    @register(dispatch_mode=Dispatch.ONE_TO_ALL)
    def init_model(self):
        # åŠ è½½ ACTOR æ¨¡å‹ï¼ˆç”¨äºè®­ç»ƒï¼‰
        self.actor_module, self.actor_optimizer, ... = self._build_model_optimizer(
            model_path=self.config.model.path,  # â† å­¦ç”Ÿæ¨¡å‹è·¯å¾„
            optim_config=self.config.actor.optim,
            ...
        )
        
        # åˆ›å»º Actor å¯¹è±¡
        self.actor = OnPolicyDistillActor(
            actor_module=self.actor_module,  # å­¦ç”Ÿæ¨¡å‹
            ...
        )
```

**ç»“è®º**: Actor åŠ è½½ **å­¦ç”Ÿæ¨¡å‹ (Qwen2.5-1.5B)**

### é—®é¢˜ 2ï¼šRollout Worker åŠ è½½ä»€ä¹ˆæ¨¡å‹ï¼Ÿ

**æ–‡ä»¶**: `recipe/gkd/megatron_workers.py` ç¬¬697-707è¡Œ

```python
class MegatronOnPolicyDistillRolloutWorker(ActorRolloutRefWorker):
    @register(dispatch_mode=Dispatch.ONE_TO_ALL)
    def init_model(self):
        # åŠ è½½ ROLLOUT æ¨¡å‹ï¼ˆç”¨äºæ¨ç†ç”Ÿæˆï¼‰
        self._build_rollout(trust_remote_code=...)
```

å…³é”®ï¼š`_build_rollout()` åŠ è½½çš„æ˜¯ä»€ä¹ˆï¼Ÿ

**çˆ¶ç±»å®ç°** (`verl/workers/megatron_workers.py` ç¬¬489-550è¡Œ):

```python
def _build_rollout(self, trust_remote_code=False):
    # ä½¿ç”¨åŒä¸€ä¸ªæ¨¡å‹è·¯å¾„
    model_config: HFModelConfig = omega_conf_to_dataclass(
        OmegaConf.create(model_config_dict), 
        dataclass_type=HFModelConfig
    )
    
    # åˆ›å»º vLLM/SGLang æ¨ç†å¼•æ“
    # è¯¥å¼•æ“ä¹ŸåŠ è½½ self.config.model.pathï¼ˆå­¦ç”Ÿæ¨¡å‹ï¼‰
    self.rollout = vLLMRollout(
        model_hf_config=self.actor_model_config,  # åŒå­¦ç”Ÿæ¨¡å‹é…ç½®
        ...
    )
```

**ç»“è®º**: Rollout ä¹ŸåŠ è½½ **å­¦ç”Ÿæ¨¡å‹ (Qwen2.5-1.5B)** ç”¨äºç”Ÿæˆåºåˆ—

---

## å†…å­˜åˆ†æ

### å­¦ç”Ÿæ¨¡å‹å†…å­˜å ç”¨

Qwen2.5-1.5B (1.5B å‚æ•°ï¼Œbfloat16):
- æ¨¡å‹å‚æ•°: 1.5B Ã— 2å­—èŠ‚ â‰ˆ **3GB**
- æ¢¯åº¦ (Actor): 3GB
- ä¼˜åŒ–å™¨çŠ¶æ€ (Adam): 3GB Ã— 2 â‰ˆ **6GB**
- KVç¼“å­˜ + æ¿€æ´»å€¼: 1-2GB
- **Actor Worker æ€»è®¡**: ~12-13GB

Rollout (æ¨ç†ä¸“ç”¨):
- æ¨¡å‹å‚æ•°: **3GB**
- KVç¼“å­˜ (æ¨ç†): 2-3GB
- **Rollout Worker æ€»è®¡**: ~5-6GB

**æ€»ä½¿ç”¨**: (13 + 6) Ã— N_workers = 19GB Ã— 1 = 19GB (åˆç†)

---

## å…³é”®å‘ç°ï¼šä¸ºä»€ä¹ˆé…ç½®æ–‡ä»¶ä¸­è¯´ teacher éœ€è¦ n_gpus_per_node?

### ç­”æ¡ˆ: è¿™æ˜¯**è¯¯å¯¼**

åœ¨ `on_policy_distill_trainer.yaml` ç¬¬280-284è¡Œ:
```yaml
teacher:
  server_ip: localhost
  server_port: 15555
  overlap_rollout: False
  n_server_workers: 1
```

è¿™é‡Œçš„ **`n_server_workers`** ä¸æ˜¯ GPU æ•°é‡ï¼Œè€Œæ˜¯ï¼š
- **åå°çº¿ç¨‹æ•°** - Teacher æœåŠ¡å™¨å†…éƒ¨çš„å¤„ç†çº¿ç¨‹æ•°
- ä¸å½±å“ GPU åˆ†é…ï¼ˆTeacher åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼‰
- å–å€¼èŒƒå›´é€šå¸¸: 1-4

---

## å®é™…é—®é¢˜è¯Šæ–­

### é—®é¢˜ Aï¼šRay åˆ†é… GPU ä¸æ­£ç¡®

**ç—‡çŠ¶**: Actor æˆ– Rollout åˆå§‹åŒ–æ—¶å¡æ­»

**å¯èƒ½åŸå› **:
1. Ray æ²¡æœ‰æ­£ç¡®åˆ†é… GPU åˆ°è¿›ç¨‹
2. å¤šä¸ª Worker äº‰ç”¨åŒä¸€å¼  GPU
3. NCCL é€šä¿¡åœ¨é”™è¯¯çš„ GPU ä¸Šè¿›è¡Œ

**æ£€æŸ¥æ–¹æ³•**:
```python
# åœ¨ Worker ä¸­æ·»åŠ è¯Šæ–­ä»£ç 
import os
print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'NOT SET')}")
print(f"LOCAL_RANK: {os.environ.get('LOCAL_RANK', 'NOT SET')}")

import torch
print(f"Available GPUs: {torch.cuda.device_count()}")
print(f"Current GPU: {torch.cuda.current_device()}")
```

### é—®é¢˜ Bï¼šåŒæ—¶åŠ è½½å­¦ç”Ÿæ¨¡å‹å¤ªæ…¢

**ç—‡çŠ¶**: init_model é˜¶æ®µå¡æ­» 20+ ç§’

**åŸå› **: è™½ç„¶ Actor å’Œ Rollout åˆ†åˆ«åœ¨ä¸åŒ GPU ä¸Šï¼Œä½†ï¼š
1. éƒ½è¦åŠ è½½åŒä¸€ä¸ªæ¨¡å‹ï¼ˆä¸‹è½½/è§£æ/è½¬æ¢ï¼‰
2. Megatron åˆå§‹åŒ–å¾ˆæ…¢ï¼ˆNCCL é€šä¿¡ï¼‰
3 æ²¡æœ‰å¹¶è¡ŒåŒ–ï¼ˆé¡ºåºåˆå§‹åŒ–ï¼‰

**ä¼˜åŒ–æ–¹å¼**:
```python
# å¯ä»¥å°è¯•å¼‚æ­¥åˆå§‹åŒ–
# æˆ–åœ¨ init_workers ä¸­æ·»åŠ å¹¶å‘æ§åˆ¶
```

---

## GPU é…ç½®å»ºè®®

### å¯¹äºå•æœº 8 å¡ + Teacher çš„åœºæ™¯

**Option 1: å½“å‰é…ç½®ï¼ˆæ¨èï¼‰**
```yaml
trainer:
  n_gpus_per_node: 1    # Actor ç”¨ 1 å¼ å¡ï¼ˆè®­ç»ƒä¸éœ€è¦å¤ªå¤šï¼‰
  nnodes: 1

rollout:
  n_gpus_per_node: 3    # Rollout ç”¨ 3 å¼ å¡ï¼ˆæ¨ç†éœ€è¦å¹¶è¡Œï¼‰
  nnodes: 1

# Teacher: å¦å¤–å¯åŠ¨ï¼Œç”¨ 4 å¼ å¡
```

GPU åˆ†å¸ƒ:
- GPU 0: Actor (è®­ç»ƒå­¦ç”Ÿæ¨¡å‹)
- GPU 1-3: Rollout (å¹¶è¡Œç”Ÿæˆåºåˆ—)
- GPU 4-7: Teacher Server (ç‹¬ç«‹è¿›ç¨‹)

**ä¼˜åŠ¿**: å……åˆ†åˆ©ç”¨ 8 å¼ å¡

---

## éªŒè¯ GPU åˆ†é…

è¿è¡Œè¿™ä¸ªè„šæœ¬ç¡®è®¤å®é™…åˆ†é…:

```python
import ray
import torch

@ray.remote(num_gpus=1)
def check_gpu():
    import os
    print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")
    print(f"GPU Count: {torch.cuda.device_count()}")
    return os.environ.get('CUDA_VISIBLE_DEVICES')

ray.init()
futures = [check_gpu.remote() for _ in range(4)]
results = ray.get(futures)
print("GPU Assignments:", results)
ray.shutdown()
```

**æœŸæœ›è¾“å‡º**:
```
GPU Assignments: ['0', '1', '2', '3']
```

å¦‚æœå‡ºç°é‡å¤ï¼ˆå¦‚ `['0', '0', '1', '1']`ï¼‰ï¼Œè¯´æ˜åˆ†é…æœ‰é—®é¢˜ã€‚

---

## æ€»ç»“

1. âœ… **Teacher é…ç½®ä¸­çš„ `n_gpus_per_node` æ— æ•ˆ** - Teacher æ˜¯ç‹¬ç«‹è¿›ç¨‹ï¼ŒGPU åˆ†é…ç”±å¯åŠ¨å‘½ä»¤æ§åˆ¶
2. âœ… **Actor å’Œ Rollout å„è‡ªåŠ è½½å®Œæ•´çš„å­¦ç”Ÿæ¨¡å‹** - è¿™æ˜¯è®¾è®¡ï¼Œç”¨äºæƒé‡åŒæ­¥
3. âœ… **å®é™… GPU åˆ†é…ç”± ResourcePoolManager å¤„ç†** - æ ¹æ® `trainer.n_gpus_per_node` å’Œ `rollout.n_gpus_per_node` åˆ†é…
4. â“ **å¡æ­»åŸå› **: éœ€è¦æ£€æŸ¥ CUDA_VISIBLE_DEVICES æ˜¯å¦æ­£ç¡®è®¾ç½®ï¼Œä»¥åŠ NCCL é€šä¿¡æ˜¯å¦æ­£å¸¸

---

## å¿«é€Ÿè¯Šæ–­

åœ¨ `recipe/gkd/megatron_workers.py` çš„ `init_model()` ä¸­æ·»åŠ :

```python
@register(dispatch_mode=Dispatch.ONE_TO_ALL)
def init_model(self):
    import os
    rank = int(os.environ.get('LOCAL_RANK', 0))
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', 'NOT SET')
    print(f"Worker {rank}: CUDA_VISIBLE_DEVICES={cuda_devices}, GPU Count={torch.cuda.device_count()}")
    
    # ç»§ç»­åŸæœ‰é€»è¾‘...
```

è¿™æ ·å¯ä»¥ç«‹å³çœ‹åˆ° GPU åˆ†é…æ˜¯å¦æ­£ç¡®ã€‚
